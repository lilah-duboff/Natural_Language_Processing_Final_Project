{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674299bb",
   "metadata": {},
   "source": [
    "# Comparing Natural Language Processing Approaches to Clustering Patents from Subsidiary Companies\n",
    "## Peter de Guzman (ped19)\n",
    "## Lilah DuBoff (lad90)\n",
    "## Christian Moreira (csm87)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1af7e",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "\n",
    "Using a dataset of patents submitted to the U.S. Patent Office(USPTO) by subsidiaries of large multinational corporations, we will perform clustering of patents into patent topic categories. Some of the NLP techniques employed in this assignment include performing data cleaning on patent text, performing dimension reduction using PCA and machine learning algorithms(Complement Naive Bayes and Support Vector Classifier) for clustering patent abstracts and titles into a set of relevant comparable topics. The motivation behind this work is to address the task of tracking innovation across publicly traded companies, especially where patents are filed under different subsidiary names(i.e. “Google” with patents under “Waymo”, “DeepMind”, “Nest”); Emerging technological advancements often occur under subsidiaries of large corporations, but are not tracked due to the multitude of subsidiary firms. This project explores classification methods beyond the traditional Cooperative Patent Classification (CPC) system, offering more flexible and insightful ways for legal specialists, researchers, and investors to explore patent content and similar innovation strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca1790",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "Large publicly traded companies are constantly innovating and investing millions of dollars in research and development to maintain a competitive edge in the marketplace while developing new products. The patents during the innovation process are often filed by the subsidiaries of these large companies. Informed investors and attorneys rely on alternative patent data to track the actions of these subsidiaries and better understand emerging trends and forecast growth across industries, but manually tracking patents can be resource intensive due to complex corporate structures between parent companies and subsidiaries. Oftentimes a large publicly traded company could have dozens to hundreds of subsidiaries, each filing patents under a separate entity. Targeting subsidiary companies requires name mapping solutions that can parse large amounts of patent data and establish connections between seemingly disparate corporate entities. For investors, scientists, and legal advisors it is instrumental to be able to quickly track a patent for a company while also evaluating novel inventions in strategic areas of the industries in which they operate. \n",
    "\n",
    "To address this, we tested the ability of two models that cluster patent text content (title and abstracts) into meaningful groups by topic. For cluster evaluation we compare model clusters to IPC Sections and Classes (see Exhibit 1 for an example of this). The models implemented in this experiment use two supervised techniques: a Complement Naive Bayes classifier and a support vector classifier (SVC) model. Both models were trained on a dataset of patent documents and evaluated using standard clustering metrics such as accuracy,predictions, and recall; Before classification the data is preprocessed to remove distracting terms(filler words) or combine  terms together (plural nouns i.e. box & boxes). The model evaluation adheres occurs relative to its actual classification group which is a combination of patent section and class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473c877",
   "metadata": {},
   "source": [
    "![PatentTaxonomy](\"PatentTaxonomy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875deed",
   "metadata": {},
   "source": [
    "insert image 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414f0c2",
   "metadata": {},
   "source": [
    "The Complement Naive Bayes classifier (or ComplementNB) is a supervised, probabilistic linear model modified from a multinomial Naive Bayes model. In the real patent data, classes are often highly imbalanced - some sections appear far more frequently than others. ComplementNB is designed to perform well on imbalanced text data, as it estimates feature weights for sparser classes, which reduces model bias and stabilizes predictions across different class types. It completes this by assuming conditional independence between words, and relying on frequency-based computations. The combination of these strategies makes the model robust, even on messy or imbalanced data, making it a strong choice for patent classifications.\n",
    "\n",
    "The support vector classifier (or LinearSVC) is another supervised machine learning model, but instead of looking at how often words appear in each class, like ComplementNB does, LinearSVC learns which combinations of words best separate one IPC section from another. For patent data, this is effective because Linear SVC can pick up on more complex and detailed language patterns in titles and abstracts. The drawback is that LinearSVC is less interpretable, and takes longer to train (marginal with the amount of data we have, but important to note for scalability and cost-efficiency). Overall, it typically outperforms a text classifying Naive Bayes model, therefore it is important to compare both to contextualize accuracy and efficiency in patent classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37914ae",
   "metadata": {},
   "source": [
    "# Evaluation of Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4991422d",
   "metadata": {
    "tags": [
     "hide-input",
     "no-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Load in libraries and data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# UPDATE: Added CountVectorizer here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3820f6ec",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# PREPROCESSING CODE\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# makes everything lowercase, removes punctuation, lemmatizes, and removes stopwords\n",
    "def clean_text(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"[^a-z\\s]\", \" \", t)\n",
    "    t = \" \".join([lemmatizer.lemmatize(word) for word in t.split() if word not in stop])\n",
    "    return t\n",
    "\n",
    "\n",
    "# load in new subset\n",
    "df_subset = pd.read_csv(\"data/top500_patents.csv\")\n",
    "\n",
    "# combine section and class, then clean text\n",
    "df_subset[\"Combined_ipc_clean\"] = (\n",
    "    df_subset[\"ipc_sections\"] + \"_\" + df_subset[\"ipc_classes\"].astype(str)\n",
    ")\n",
    "\n",
    "# combine title and abstract for easier classification\n",
    "df_subset[\"text_clean\"] = (\n",
    "    (df_subset[\"patent_title\"] + \": \" + df_subset[\"patent_abstract\"])\n",
    "    .astype(str)\n",
    "    .apply(clean_text)\n",
    ")\n",
    "\n",
    "# Additional Data Cleaning\n",
    "\n",
    "# drop under 50 observations\n",
    "df_subset = df_subset.groupby(\"Combined_ipc_clean\").filter(lambda x: len(x) >= 50)\n",
    "\n",
    "# remove the duplicate rows\n",
    "dups_to_remove = [\"H_4\", \"G_1\", \"B_1\", \"G_6\", \"C_7\"]\n",
    "for dup in dups_to_remove:\n",
    "    df_subset = df_subset[df_subset[\"Combined_ipc_clean\"] != dup]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da323739",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data from CNB Conditional Word Distributions Learned From Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77fb9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train CNB on our real data so we can generate the synthetic data\n",
    "\n",
    "# Use inputs and labels from the real dataset\n",
    "X_bayes = df_subset[\"text_clean\"]\n",
    "y_bayes = df_subset[\"Combined_ipc_clean\"]\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train_bayes, X_test_bayes, y_train_bayes, y_test_bayes = train_test_split(\n",
    "    X_bayes, y_bayes, test_size=0.20, stratify=y_bayes, random_state=42\n",
    ")\n",
    "\n",
    "# Use CountVectorizer and fit the model\n",
    "vec = CountVectorizer(stop_words=\"english\")\n",
    "X_train_vec = vec.fit_transform(X_train_bayes)\n",
    "X_test_vec = vec.transform(X_test_bayes)\n",
    "\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train_vec, y_train_bayes)\n",
    "\n",
    "# Evaluate the CNB model on real data\n",
    "preds = cnb.predict(X_test_vec)\n",
    "report_dict_realdata = classification_report(y_test_bayes, preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e025f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNB-Based way to generate synthetic text from the model's learned conditional word distributions\n",
    "\n",
    "# compute class priors from real data\n",
    "\n",
    "class_counts = y_train_bayes.value_counts()\n",
    "class_priors = class_counts / class_counts.sum()\n",
    "# print(\"Real class priors:\")\n",
    "# print(class_priors)\n",
    "\n",
    "\n",
    "def sample_docs_from_cnb_with_real_priors(\n",
    "    cnb, vectorizer, class_priors, n_total_docs=5000, doc_len_range=(50, 120)\n",
    "):\n",
    "\n",
    "    classes = cnb.classes_\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # normalize\n",
    "    raw_probs = np.exp(cnb.feature_log_prob_)\n",
    "    word_probs = raw_probs / raw_probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "    synthetic_labels = np.random.choice(\n",
    "        class_priors.index, size=n_total_docs, p=class_priors.values\n",
    "    )\n",
    "\n",
    "    synthetic_texts = []\n",
    "\n",
    "    for cls in synthetic_labels:\n",
    "        # find  index (number)\n",
    "        c_index = np.where(classes == cls)[0][0]\n",
    "\n",
    "        # probability distribution for words\n",
    "        p_w_given_c = word_probs[c_index]\n",
    "\n",
    "        # sample doc len\n",
    "        L = np.random.randint(*doc_len_range)\n",
    "\n",
    "        # sample word indices\n",
    "        sampled_idx = np.random.choice(len(vocab), size=L, replace=True, p=p_w_given_c)\n",
    "\n",
    "        # convert to tokens\n",
    "        doc_words = [vocab[i] for i in sampled_idx]\n",
    "        synthetic_texts.append(\" \".join(doc_words))\n",
    "\n",
    "    return pd.Series(synthetic_texts), pd.Series(synthetic_labels)\n",
    "\n",
    "\n",
    "# Generate the synthetic dataset\n",
    "X_syn, y_syn = sample_docs_from_cnb_with_real_priors(\n",
    "    cnb=cnb,\n",
    "    vectorizer=vec,\n",
    "    class_priors=class_priors,\n",
    "    n_total_docs=10000,  # going to make a lot\n",
    "    doc_len_range=(50, 120),\n",
    ")\n",
    "\n",
    "# print(\"Synthetic dataset size:\", len(X_syn))\n",
    "# print(\"Per-class counts:\")\n",
    "# print(y_syn.value_counts())\n",
    "\n",
    "# print(\"Synthetic class distribution:\")\n",
    "# print(y_syn.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7cb96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;clf&#x27;, LinearSVC(dual=False, max_iter=5000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;vec&#x27;, ...), (&#x27;clf&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"vec__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;english&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.int64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearSVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"clf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;squared_hinge&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">5000</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer(stop_words='english')),\n",
       "                ('clf', LinearSVC(dual=False, max_iter=5000))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train_syn, X_test_syn, y_train_syn, y_test_syn = train_test_split(\n",
    "    X_syn, y_syn, test_size=0.2, stratify=y_syn, random_state=42\n",
    ")\n",
    "\n",
    "# Train CNB on synthetic data\n",
    "cnb_synth = Pipeline(\n",
    "    [\n",
    "        (\"vec\", CountVectorizer(stop_words=\"english\")),\n",
    "        (\"nb\", ComplementNB()),\n",
    "    ]\n",
    ")\n",
    "cnb_synth.fit(X_train_syn, y_train_syn)\n",
    "\n",
    "# Train SVC on synthetic data\n",
    "svc_synth = Pipeline(\n",
    "    [\n",
    "        (\"vec\", CountVectorizer(stop_words=\"english\")),\n",
    "        (\"clf\", LinearSVC(max_iter=5000, dual=False)),\n",
    "    ]\n",
    ")\n",
    "svc_synth.fit(X_train_syn, y_train_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "733fa63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic Data Performance:\n",
      "CNB accuracy: 0.5035\n",
      "SVC accuracy: 0.4930\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cnb_acc = cnb_synth.score(X_test_syn, y_test_syn)\n",
    "svc_acc = svc_synth.score(X_test_syn, y_test_syn)\n",
    "\n",
    "print(\"Synthetic Data Performance:\")\n",
    "print(f\"CNB accuracy: {cnb_acc:.4f}\")\n",
    "print(f\"SVC accuracy: {svc_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94b7fa",
   "metadata": {},
   "source": [
    "# Application of Solution on Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf9d361",
   "metadata": {},
   "source": [
    "To conduct this experiment, we collected publicly available patent data from the U.S. Patent and Trademark Office (USPTO). First, we researched the thirty companies listed in the Dow Jones Industrial Average, a stock market index of prominent companies. Referencing this list, we collected the legal incorporated names of subsidiaries for each large company. Finally, we used this list of subsidiary names as input for the USPTO API which returned the patent title and abstract for each subsidiary company. \n",
    "\n",
    "We conducted multiple data pre-processing steps to clean the data and improve accuracy. First, we removed duplicate patent observations. We also combined the “class” and “section” labels for each patent to produce more meaningful clusters. Both the “class” and “section” labels identify patents by industry field and topic. We additionally subset the data to only predict classes that have more than fifty observations. As patent classifications can be very niche, we expect to observe many patents that have multiple classifications but only one or two observations. This sort of data does not typically perform well for machine learning problems, so we dropped them. \n",
    "\n",
    "We also performed multiple steps to make the text easier to classify. We first converted all text to lowercase and used the Python Natural Language Toolkit (“nltk”) package to remove stopwords such as “the”, “and”, etc. We also used a lemmatizer which converts all the words in our dataset to their dictionary form (a lemma). This improves the accuracy by treating words with similar meanings the same, reducing data redundancy and making the text more consistent. Finally, to quicken the training process and reduce the compute load on our machines, we reduced the dataset to the most recent 500 patents. We then created training and test splits from this smaller dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60fd9e",
   "metadata": {},
   "source": [
    "**Complement Naive Bayes Classifier:**\n",
    "\n",
    "In the Complement Naive Bayes pipeline, we also use the TF-IDF vectorizer, as above. \n",
    "\n",
    "After these preprocessing steps, the ComplementNB classifier achieved an overall accuracy of 69%. Given the 47 classes in our dataset and the imbalanced nature of patent classification, this performance exceeded our expectations. \n",
    "\n",
    "The macro average F1 score, which treats classes equally, was 51%. This indicates that we have imbalance issues in our dataset. The weighted F1 score, which accounts for imbalance by weighing each class by how frequent it is, was 65%. Since the weighted average is high, we can conclude that the model performed well on classes that are more common. However, the macro average was much lower, displaying that the model performs poorly on rare classes. When reviewing the classification report below, we can observe that the F1 score was consistently higher for classes with more support, or a higher number of true samples in the class. This matches our expectation that the model’s metrics are more stable for classes with more support. Poor results occurred more often for classes with support of fewer than 20 observations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80b22a",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes Classifier\n",
    "# Inputs and labels\n",
    "X_bayes = df_subset[\"text_clean\"]\n",
    "y_bayes = df_subset[\"Combined_ipc_clean\"]\n",
    "\n",
    "X_train_bayes, X_test_bayes, y_train_bayes, y_test_bayes = train_test_split(\n",
    "    X_bayes, y_bayes, test_size=0.20, stratify=y_bayes, random_state=42\n",
    ")\n",
    "\n",
    "# Build model\n",
    "# UPDATE: Swapped TF-IDF for CountVectorizer\n",
    "class_model = Pipeline(\n",
    "    [\n",
    "        (\"vec\", CountVectorizer(stop_words=\"english\", max_features=5000)),\n",
    "        (\"nb\", ComplementNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train\n",
    "class_model.fit(X_train_bayes, y_train_bayes)\n",
    "\n",
    "# Evaluate\n",
    "preds = class_model.predict(X_test_bayes)\n",
    "\n",
    "# Compute report as dict\n",
    "report_dict_realdata_cnb = classification_report(y_test_bayes, preds, output_dict=True)\n",
    "\n",
    "# Convert to DataFrame\n",
    "report_df_real_cnb = pd.DataFrame(report_dict_realdata_cnb).transpose()\n",
    "\n",
    "# Round numbers for readability\n",
    "report_df_real_cnb = report_df_real_cnb.round(4)\n",
    "\n",
    "# print(\"Real Data Results (CountVectorizer):\")\n",
    "# print(tabulate(report_df_real_cnb, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb3b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learning curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# UPDATE: Ensure CountVectorizer is imported if running this cell independently\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=8,\n",
    "        n_jobs=-1,\n",
    "        train_sizes=np.linspace(0.05, 1.0, 25),\n",
    "        scoring=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    train_mean = train_scores.mean(axis=1)\n",
    "    test_mean = test_scores.mean(axis=1)\n",
    "    train_std = train_scores.std(axis=1)\n",
    "    test_std = test_scores.std(axis=1)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training Set Size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    # Train accuracy\n",
    "    plt.plot(train_sizes, train_mean, label=\"Training Accuracy\")\n",
    "    plt.fill_between(\n",
    "        train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2\n",
    "    )\n",
    "\n",
    "    # Validation accuracy\n",
    "    plt.plot(train_sizes, test_mean, label=\"Validation Accuracy\")\n",
    "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create models\n",
    "# UPDATE: Swapped TF-IDF for CountVectorizer\n",
    "svc_model = Pipeline(\n",
    "    [\n",
    "        (\"vec\", CountVectorizer(stop_words=\"english\")),\n",
    "        (\"clf\", LinearSVC(max_iter=5000, dual=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# UPDATE: Swapped TF-IDF for CountVectorizer\n",
    "cnb_model = Pipeline(\n",
    "    [\n",
    "        (\"vec\", CountVectorizer(stop_words=\"english\", max_features=5000)),\n",
    "        (\"nb\", ComplementNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot learning curves\n",
    "plot_learning_curve(\n",
    "    cnb_model, \"Learning Curve: Complement Naive Bayes (CountVec)\", X_bayes, y_bayes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686c044",
   "metadata": {},
   "source": [
    "As we can see from the above plot, as the training set size increases, the training accuracy drops and the validation accuracy for the model grows. This aligns with our expectations because Complement Naive Bayes is a high-bias and low-variance model like its other Naive Bayes peers. When the training data is small, the model can overfit to the word distributions. As the training dataset size increases, the model overfits less, reducing training accuracy but increasing validation accuracy because the distribution estimates improve. In particular, Complement Naive Bayes is designed to benefit from more data, and this positive growth in validation accuracy with more training data can be observed above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a15c563",
   "metadata": {},
   "source": [
    "**Support Vector Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d106243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC code\n",
    "# Define X and y\n",
    "X_svc = df_subset[\"text_clean\"]\n",
    "y_svc = df_subset[\"Combined_ipc_clean\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train_svc, X_test_svc, y_train_svc, y_test_svc = train_test_split(\n",
    "    X_svc, y_svc, test_size=0.2, stratify=y_svc, random_state=42\n",
    ")\n",
    "\n",
    "# LinearSVC model\n",
    "# UPDATE: Swapped TF-IDF for CountVectorizer\n",
    "svc_model_real = Pipeline(\n",
    "    [\n",
    "        (\"vec\", CountVectorizer(stop_words=\"english\")),\n",
    "        (\"clf\", LinearSVC(class_weight=\"balanced\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "svc_model_real.fit(X_train_svc, y_train_svc)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svcreal = svc_model_real.predict(X_test_svc)\n",
    "\n",
    "# Evaluation\n",
    "# Compute report as dict\n",
    "report_dict_realdata_svc = classification_report(\n",
    "    y_test_svc, y_pred_svcreal, output_dict=True\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "report_df_real_svc = pd.DataFrame(report_dict_realdata_svc).transpose()\n",
    "\n",
    "# Round numbers for readability\n",
    "report_df_real_svc = report_df_real_svc.round(4)\n",
    "\n",
    "# print(\"Real Data Results - SVC (CountVectorizer):\")\n",
    "# print(tabulate(report_df_real_svc, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing SVC\n",
    "# major convergence warning here due to lack of iterations\n",
    "# went as high as 500k with no change in learning curve for training accuracy\n",
    "plot_learning_curve(svc_model_real, \"Learning Curve: LinearSVC\", X_svc, y_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22053e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing CNB with Synthetic Data\n",
    "plot_learning_curve(\n",
    "    cnb_synth,\n",
    "    \"Learning Curve: Complement Naive Bayes with Synthetic Data\",\n",
    "    X_syn,\n",
    "    y_syn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8832febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing SVC with Synthetic Data\n",
    "plot_learning_curve(\n",
    "    svc_synth, \"Learning Curve: LinearSVC with Synthetic Data\", X_syn, y_syn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11574002",
   "metadata": {},
   "source": [
    "## Summary Table of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabulate import tabulate\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Data Preparation\n",
    "# -----------------------------------\n",
    "\n",
    "# Real data\n",
    "X_real = df_subset[\"text_clean\"]\n",
    "y_real = df_subset[\"Combined_ipc_clean\"]\n",
    "\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(\n",
    "    X_real, y_real, test_size=0.2, stratify=y_real, random_state=42\n",
    ")\n",
    "\n",
    "# Synthetic data (assumes X_syn, y_syn already generated)\n",
    "X_train_syn, X_test_syn, y_train_syn, y_test_syn = train_test_split(\n",
    "    X_syn, y_syn, test_size=0.2, stratify=y_syn, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    t0 = time.time()\n",
    "    preds = model.predict(X_test)\n",
    "    test_time = time.time() - t0\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    macro_f1 = f1_score(y_test, preds, average=\"macro\")\n",
    "\n",
    "    return acc, macro_f1, train_time, test_time\n",
    "\n",
    "\n",
    "vec = CountVectorizer(stop_words=\"english\", max_features=50000)\n",
    "\n",
    "vec.fit(pd.concat([X_train_real, X_train_syn]))\n",
    "\n",
    "# Transform datasets\n",
    "X_train_real_vec = vec.transform(X_train_real)\n",
    "X_test_real_vec = vec.transform(X_test_real)\n",
    "X_train_syn_vec = vec.transform(X_train_syn)\n",
    "X_test_syn_vec = vec.transform(X_test_syn)\n",
    "\n",
    "# train and evaluate models on the synthetic data and the real data so we can make summary table\n",
    "\n",
    "results = []\n",
    "\n",
    "# CNB - Real\n",
    "cnbr = ComplementNB()\n",
    "acc, f1, t_train, t_test = evaluate_model(\n",
    "    cnbr, X_train_real_vec, y_train_real, X_test_real_vec, y_test_real\n",
    ")\n",
    "results.append([\"REAL\", \"CNB\", acc, f1, t_train, t_test])\n",
    "\n",
    "# SVC--Real\n",
    "svcr = LinearSVC()\n",
    "acc, f1, t_train, t_test = evaluate_model(\n",
    "    svcr, X_train_real_vec, y_train_real, X_test_real_vec, y_test_real\n",
    ")\n",
    "results.append([\"REAL\", \"SVC\", acc, f1, t_train, t_test])\n",
    "\n",
    "# CNB - Synthetic\n",
    "cnbs = ComplementNB()\n",
    "acc, f1, t_train, t_test = evaluate_model(\n",
    "    cnbs, X_train_syn_vec, y_train_syn, X_test_syn_vec, y_test_syn\n",
    ")\n",
    "results.append([\"SYNTHETIC\", \"CNB\", acc, f1, t_train, t_test])\n",
    "\n",
    "# SVC - Synthetic\n",
    "svcs = LinearSVC()\n",
    "acc, f1, t_train, t_test = evaluate_model(\n",
    "    svcs, X_train_syn_vec, y_train_syn, X_test_syn_vec, y_test_syn\n",
    ")\n",
    "results.append([\"SYNTHETIC\", \"SVC\", acc, f1, t_train, t_test])\n",
    "\n",
    "# create the summary table\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\n",
    "        \"Dataset\",\n",
    "        \"Model\",\n",
    "        \"Accuracy\",\n",
    "        \"Macro-F1\",\n",
    "        \"Train Time (s)\",\n",
    "        \"Test Time (s)\",\n",
    "    ],\n",
    ")\n",
    "# round to 4 like in appendix tables\n",
    "summary_df[[\"Accuracy\", \"Macro-F1\", \"Train Time (s)\", \"Test Time (s)\"]] = summary_df[\n",
    "    [\"Accuracy\", \"Macro-F1\", \"Train Time (s)\", \"Test Time (s)\"]\n",
    "].round(4)\n",
    "\n",
    "print(\"==== Summary Table for All Experiments ====\")\n",
    "print(tabulate(summary_df, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af17146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional SVC plots\n",
    "def normalize_ipc_label(label: str) -> str:\n",
    "    # Handle composite labels (e.g., H;G:06) by taking the first section\n",
    "    if \";\" in label:\n",
    "        label = label.split(\";\")[0]\n",
    "\n",
    "    # Extract the IPC Section (A, B, C...)\n",
    "    match = re.search(r\"^[A-H]\", label)  # IPC sections go from A to H\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "# Normalize the labels with the function above\n",
    "y_sections = [normalize_ipc_label(lbl) for lbl in y_test_svc]\n",
    "\n",
    "\n",
    "# Vectorize text using CountVectorizer\n",
    "# UPDATE: Swapped TF-IDF for CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words=\"english\")\n",
    "X_counts = vectorizer.fit_transform(X_test_svc)\n",
    "\n",
    "# Perform PCA to reduce to 2D\n",
    "pca = PCA(n_components=2)\n",
    "# UPDATE: transform the counts, not tfidf\n",
    "X_2d = pca.fit_transform(X_counts.toarray())\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "pca_df = pd.DataFrame({\"PC1\": X_2d[:, 0], \"PC2\": X_2d[:, 1], \"IPC_Section\": y_sections})\n",
    "sorted_labels = sorted(pca_df[\"IPC_Section\"].unique())\n",
    "\n",
    "# plot everything together first to see overall clusters\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    hue=\"IPC_Section\",\n",
    "    hue_order=sorted_labels,\n",
    "    palette=\"tab10\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "plt.title(\"Patent Text Clusters by IPC Section (CountVectorizer + PCA)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's plot each section separately\n",
    "\n",
    "unique_sections = sorted(pca_df[\"IPC_Section\"].unique())\n",
    "palette = sns.color_palette(\"tab10\", len(unique_sections))\n",
    "color_map = {sec: palette[i] for i, sec in enumerate(unique_sections)}\n",
    "\n",
    "# 6. Plot each section separately using its assigned color\n",
    "for section in unique_sections:\n",
    "    pca_df_subset = pca_df[pca_df[\"IPC_Section\"] == section]\n",
    "    count = (pca_df_subset[\"IPC_Section\"] == section).sum()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(\n",
    "        data=pca_df_subset, x=\"PC1\", y=\"PC2\", s=60, alpha=0.8, color=color_map[section]\n",
    "    )\n",
    "\n",
    "    plt.title(\n",
    "        f\"Cluster Plot for IPC Section: {section}, ({count} samples)\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Show legend with single color\n",
    "    plt.scatter([], [], color=color_map[section], label=f\"Section {section}\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"tab10\", len(unique_sections))\n",
    "color_map = {sec: palette[i] for i, sec in enumerate(unique_sections)}\n",
    "\n",
    "# Shared axes limits (FIXED: use pca_df, not df)\n",
    "x_min, x_max = pca_df[\"PC1\"].min(), pca_df[\"PC1\"].max()\n",
    "y_min, y_max = pca_df[\"PC2\"].min(), pca_df[\"PC2\"].max()\n",
    "\n",
    "n = len(unique_sections)\n",
    "cols = 2\n",
    "rows = math.ceil(n / cols)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 5 * rows), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, section in enumerate(unique_sections):\n",
    "    ax = axes[i]\n",
    "    # FIXED: use pca_df here\n",
    "    df_sub = pca_df[pca_df[\"IPC_Section\"] == section]\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=df_sub, x=\"PC1\", y=\"PC2\", s=25, alpha=0.8, color=color_map[section], ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"IPC Section Label {section}, with ({len(df_sub)}) Unique Patents\", fontsize=14\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", labelbottom=True, labelleft=True)\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80848bf",
   "metadata": {},
   "source": [
    "# Pros and Cons of the Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5cce44",
   "metadata": {},
   "source": [
    "**Complement Naive Bayes Classifier:**\n",
    "The ComplementNB classifier was chosen because this variant of the Naive Bayes algorithm performs better on imbalanced datasets and text classification problems than the standard Multinomial Naive Bayes algorithm. This is important in contexts like patent classification, where IPC sections and labels for subsidiary patents appear much more frequently than others, or patents fall into multiple categories. The time difference between the two models was marginal, each taking only 1-2 seconds to run. However, some factors pose difficulties when using the ComplementNB classifier. \n",
    "\n",
    "Additionally, Naive Bayes does not take into account word order, grammar rules, or common phrases. It treats input text simply like a bag of words and ignores human language rules. ComplementNB can only learn from words it has seen and is highly dependent on tokenization and preprocessing. The bag of words approach can hinder model performance, as evidenced by potential misclassifications where documents contain similar vocabulary but differ in technical function, resulting in the model grouping them into the same IPC class despite their conceptual differences. This is critical to patent classification because abstracts often contain domain-specific terms, which may be down-weighted if preprocessing doesn’t take it into account. In our model, this is evidenced by improved accuracy scores after iterations of data cleaning steps, including lemmatization and stop-word removal, which shows the model’s dependence on careful feature engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172cda3f",
   "metadata": {},
   "source": [
    "**Support Vector Classifier:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff2ea8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3de5d4d6",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b20e6c",
   "metadata": {},
   "source": [
    "### Tables for Experiment with Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4773d7c",
   "metadata": {},
   "source": [
    "**Complement Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a93b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "  \n",
    "\n",
    "#need this function to produce appendix output\n",
    "\n",
    "def full_classification_table(model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    report_dict = classification_report(y_test, preds, output_dict=True)\n",
    "\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4)\n",
    "\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bdb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbs = ComplementNB()\n",
    "\n",
    "report_syn_cnb = full_classification_table(\n",
    "\n",
    "cnbs, X_train_syn_vec, y_train_syn, X_test_syn_vec, y_test_syn\n",
    "\n",
    ")\n",
    "\n",
    "  \n",
    "\n",
    "print(\"=== Synthetic Data — CNB Classification Report ===\")\n",
    "\n",
    "print(tabulate(report_syn_cnb, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff81e7f",
   "metadata": {},
   "source": [
    "**Support Vector Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "svcs = LinearSVC()\n",
    "\n",
    "report_syn_svc = full_classification_table(\n",
    "\n",
    "svcs, X_train_syn_vec, y_train_syn, X_test_syn_vec, y_test_syn\n",
    "\n",
    ")\n",
    "\n",
    "  \n",
    "\n",
    "print(\"=== Synthetic Data — SVC Classification Report ===\")\n",
    "\n",
    "print(tabulate(report_syn_svc, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f368386",
   "metadata": {},
   "source": [
    "### Tables for Experiment with Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46feb4",
   "metadata": {},
   "source": [
    "**Complement Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19703b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real Data Results (CountVectorizer):\")\n",
    "print(tabulate(report_df_real_cnb, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee544bb5",
   "metadata": {},
   "source": [
    "**Support Vector Classifier**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real Data Results - SVC (CountVectorizer):\")\n",
    "print(tabulate(report_df_real_svc, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
